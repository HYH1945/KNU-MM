#!/usr/bin/env python3
"""
OpenCV ë””ìŠ¤í”Œë ˆì´ ë§¤ë‹ˆì €
ë¼ì´ë¸Œ ì˜ìƒ ëª¨ë“œ(webcam, network)ì—ì„œ ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í™”ë©´ê³¼ ë¶„ì„ ê²°ê³¼ë¥¼ ì˜¤ë²„ë ˆì´ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
"""

import cv2
import numpy as np
import threading
import time
from typing import Optional, Dict, Any, Tuple
from dataclasses import dataclass
from collections import deque


@dataclass
class OverlayResult:
    """ì˜¤ë²„ë ˆì´ì— í‘œì‹œí•  ë¶„ì„ ê²°ê³¼"""
    text: str
    situation: str
    emotion: str
    urgency: str
    is_emergency: bool
    timestamp: float


class OpenCVDisplay:
    """OpenCV ê¸°ë°˜ ì‹¤ì‹œê°„ ë””ìŠ¤í”Œë ˆì´"""
    
    def __init__(self, window_name: str = "ContextLLM - Live View"):
        self.window_name = window_name
        self.running = False
        self.frame = None
        self.frame_lock = threading.Lock()
        self.display_thread = None
        
        # ê²°ê³¼ ì˜¤ë²„ë ˆì´
        self.current_result: Optional[OverlayResult] = None
        self.result_display_time = 5.0  # ê²°ê³¼ í‘œì‹œ ì‹œê°„ (ì´ˆ)
        
        # ìƒ‰ìƒ ì •ì˜ (BGR)
        self.colors = {
            'critical': (0, 0, 220),      # ë¹¨ê°•
            'high': (0, 127, 255),        # ì£¼í™©
            'medium': (0, 200, 255),      # ë…¸ë‘
            'low': (0, 200, 0),           # ì´ˆë¡
            'text': (255, 255, 255),      # í°ìƒ‰
            'bg': (30, 30, 30),           # ì–´ë‘ìš´ ë°°ê²½
        }
        
        # í•œê¸€ í°íŠ¸ (ì‹œìŠ¤í…œì— ë”°ë¼ ë‹¤ë¦„)
        self.font = cv2.FONT_HERSHEY_SIMPLEX
        self.font_scale = 0.6
        self.font_thickness = 2
        
        # ìœˆë„ìš° ìƒì„± í”Œë˜ê·¸
        self.window_created = False
    
    def start(self, video_source=None):
        """ë””ìŠ¤í”Œë ˆì´ ì‹œì‘"""
        if self.running:
            return
        
        self.running = True
        self.video_source = video_source
        
        print(f"ğŸ–¥ï¸  OpenCV ë””ìŠ¤í”Œë ˆì´ ì‹œì‘: '{self.window_name}'")
        print("   ESC ë˜ëŠ” 'q' í‚¤ë¡œ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")
    
    def is_running(self):
        """ë””ìŠ¤í”Œë ˆì´ ì‹¤í–‰ ìƒíƒœ ë°˜í™˜"""
        return self.running
    
    def stop(self):
        """ë””ìŠ¤í”Œë ˆì´ ì¤‘ì§€"""
        self.running = False
        if self.window_created:
            cv2.destroyAllWindows()
            self.window_created = False
    
    def update_frame(self, frame: np.ndarray):
        """í”„ë ˆì„ ì—…ë°ì´íŠ¸"""
        with self.frame_lock:
            self.frame = frame.copy() if frame is not None else None
    
    def update_result(self, result: Dict[str, Any]):
        """ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸"""
        analysis = result.get('multimodal_analysis', {})
        
        # ê¸´ê¸‰ë„ ë ˆë²¨ ê²°ì •
        is_emergency = analysis.get('is_emergency', False)
        urgency = analysis.get('urgency_level', 'LOW')
        
        if is_emergency:
            level = 'critical'
        elif urgency in ['HIGH', 'ë†’ìŒ']:
            level = 'high'
        elif urgency in ['MEDIUM', 'ì¤‘ê°„']:
            level = 'medium'
        else:
            level = 'low'
        
        self.current_result = OverlayResult(
            text=result.get('transcribed_text', ''),
            situation=analysis.get('situation_type', 'N/A'),
            emotion=analysis.get('emotion', 'N/A'),
            urgency=level,
            is_emergency=is_emergency,
            timestamp=time.time()
        )
    
    def render(self):
        """ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ í˜¸ì¶œ - í”„ë ˆì„ ë Œë”ë§ ë° í‚¤ ì…ë ¥ ì²˜ë¦¬"""
        # í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
        with self.frame_lock:
            if self.frame is not None:
                display_frame = self.frame.copy()
            else:
                # ë¹ˆ í”„ë ˆì„ (ëŒ€ê¸° í™”ë©´)
                display_frame = self._create_waiting_frame()
        
        # ì˜¤ë²„ë ˆì´ ì¶”ê°€
        display_frame = self._add_overlay(display_frame)
        
        # ì²« ë Œë”ë§ ì‹œ ìœˆë„ìš° ìƒì„±
        if not self.window_created:
            cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
            cv2.resizeWindow(self.window_name, 800, 600)
            self.window_created = True
        
        # í™”ë©´ì— í‘œì‹œ
        cv2.imshow(self.window_name, display_frame)
        
        # í‚¤ ì…ë ¥ ì²˜ë¦¬
        key = cv2.waitKey(30) & 0xFF
        if key == 27 or key == ord('q'):  # ESC or 'q'
            self.running = False
            return False
        
        return self.running
    
    def _create_waiting_frame(self) -> np.ndarray:
        """ëŒ€ê¸° í™”ë©´ ìƒì„±"""
        frame = np.zeros((480, 640, 3), dtype=np.uint8)
        frame[:] = self.colors['bg']
        
        # ì¤‘ì•™ì— í…ìŠ¤íŠ¸
        text = "Waiting for video..."
        text_size = cv2.getTextSize(text, self.font, 1, 2)[0]
        x = (frame.shape[1] - text_size[0]) // 2
        y = (frame.shape[0] + text_size[1]) // 2
        cv2.putText(frame, text, (x, y), self.font, 1, (100, 100, 100), 2)
        
        return frame
    
    def _add_overlay(self, frame: np.ndarray) -> np.ndarray:
        """ë¶„ì„ ê²°ê³¼ ì˜¤ë²„ë ˆì´ ì¶”ê°€"""
        h, w = frame.shape[:2]
        
        # ìƒë‹¨ ìƒíƒœë°”
        cv2.rectangle(frame, (0, 0), (w, 40), self.colors['bg'], -1)
        cv2.putText(frame, "ContextLLM Live", (10, 28), self.font, 0.7, self.colors['text'], 2)
        
        # í˜„ì¬ ì‹œê°„ í‘œì‹œ
        current_time = time.strftime("%H:%M:%S")
        time_text_size = cv2.getTextSize(current_time, self.font, 0.6, 1)[0]
        cv2.putText(frame, current_time, (w - time_text_size[0] - 10, 28), 
                   self.font, 0.6, self.colors['text'], 1)
        
        # ë¶„ì„ ê²°ê³¼ ì˜¤ë²„ë ˆì´
        if self.current_result:
            elapsed = time.time() - self.current_result.timestamp
            
            if elapsed < self.result_display_time:
                self._draw_result_overlay(frame, self.current_result)
            else:
                # ì‹œê°„ì´ ì§€ë‚˜ë©´ ê²°ê³¼ ì œê±°
                pass
        
        return frame
    
    def _draw_result_overlay(self, frame: np.ndarray, result: OverlayResult):
        """ë¶„ì„ ê²°ê³¼ ë°•ìŠ¤ ê·¸ë¦¬ê¸°"""
        h, w = frame.shape[:2]
        
        # ìƒ‰ìƒ ê²°ì •
        color = self.colors.get(result.urgency, self.colors['low'])
        
        # ê¸´ê¸‰ ìƒí™©ì´ë©´ í…Œë‘ë¦¬ ê¹œë¹¡ì„ íš¨ê³¼
        if result.is_emergency:
            if int(time.time() * 2) % 2 == 0:
                cv2.rectangle(frame, (5, 5), (w-5, h-5), self.colors['critical'], 4)
        
        # í•˜ë‹¨ ê²°ê³¼ ë°•ìŠ¤ ë°°ê²½
        box_height = 120
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, h - box_height), (w, h), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # ì¢Œì¸¡ ìƒ‰ìƒ ë°”
        cv2.rectangle(frame, (0, h - box_height), (8, h), color, -1)
        
        # í…ìŠ¤íŠ¸ í‘œì‹œ
        y_offset = h - box_height + 25
        line_height = 25
        
        # ìŒì„± í…ìŠ¤íŠ¸
        text_line = f"Voice: {result.text[:40]}..." if len(result.text) > 40 else f"Voice: {result.text}"
        cv2.putText(frame, text_line, (15, y_offset), 
                   self.font, self.font_scale, self.colors['text'], self.font_thickness)
        y_offset += line_height
        
        # ìƒí™© ìœ í˜•
        cv2.putText(frame, f"Situation: {result.situation}", (15, y_offset),
                   self.font, self.font_scale, color, self.font_thickness)
        y_offset += line_height
        
        # ê°ì • ìƒíƒœ
        cv2.putText(frame, f"Emotion: {result.emotion}", (15, y_offset),
                   self.font, self.font_scale, self.colors['text'], self.font_thickness)
        
        # ìš°ì¸¡ ìƒë‹¨ì— ê¸´ê¸‰ë„ ë°°ì§€
        if result.is_emergency:
            badge_text = "EMERGENCY"
            badge_color = self.colors['critical']
        else:
            badge_text = result.urgency.upper()
            badge_color = color
        
        badge_size = cv2.getTextSize(badge_text, self.font, 0.8, 2)[0]
        badge_x = w - badge_size[0] - 20
        badge_y = h - box_height + 30
        
        # ë°°ì§€ ë°°ê²½
        cv2.rectangle(frame, 
                     (badge_x - 10, badge_y - badge_size[1] - 5),
                     (badge_x + badge_size[0] + 10, badge_y + 5),
                     badge_color, -1)
        cv2.putText(frame, badge_text, (badge_x, badge_y),
                   self.font, 0.8, (255, 255, 255), 2)
    
    def is_running(self) -> bool:
        """ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸"""
        return self.running


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_display_instance: Optional[OpenCVDisplay] = None


def get_display() -> OpenCVDisplay:
    """ì‹±ê¸€í†¤ ë””ìŠ¤í”Œë ˆì´ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _display_instance
    if _display_instance is None:
        _display_instance = OpenCVDisplay()
    return _display_instance


def start_display():
    """ë””ìŠ¤í”Œë ˆì´ ì‹œì‘"""
    get_display().start()


def stop_display():
    """ë””ìŠ¤í”Œë ˆì´ ì¤‘ì§€"""
    if _display_instance:
        _display_instance.stop()


def update_frame(frame: np.ndarray):
    """í”„ë ˆì„ ì—…ë°ì´íŠ¸"""
    if _display_instance and _display_instance.is_running():
        _display_instance.update_frame(frame)


def update_result(result: Dict[str, Any]):
    """ê²°ê³¼ ì—…ë°ì´íŠ¸"""
    if _display_instance and _display_instance.is_running():
        _display_instance.update_result(result)


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸: ì›¹ìº ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    print("OpenCV ë””ìŠ¤í”Œë ˆì´ í…ŒìŠ¤íŠ¸")
    
    display = OpenCVDisplay()
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        exit(1)
    
    display.start()
    
    # í…ŒìŠ¤íŠ¸ ê²°ê³¼
    test_result = {
        'transcribed_text': 'í…ŒìŠ¤íŠ¸ ìŒì„±ì…ë‹ˆë‹¤',
        'multimodal_analysis': {
            'situation_type': 'ì •ìƒ',
            'emotion': 'ì¤‘ë¦½',
            'urgency_level': 'LOW',
            'is_emergency': False
        }
    }
    
    try:
        while display.is_running():
            ret, frame = cap.read()
            if ret:
                display.update_frame(frame)
            
            # 5ì´ˆë§ˆë‹¤ ê²°ê³¼ ì—…ë°ì´íŠ¸
            if int(time.time()) % 5 == 0:
                display.update_result(test_result)
            
            time.sleep(0.03)
    except KeyboardInterrupt:
        pass
    finally:
        display.stop()
        cap.release()
