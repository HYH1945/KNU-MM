# ìŒì„± ì¸ì‹ + LLM ë¶„ì„ ì„¤ì • ê°€ì´ë“œ

## ğŸ“‹ êµ¬ì¡°

```
ìŒì„± ë…¹ìŒ (10ì´ˆ)
    â†“
Whisper ë³€í™˜ (ìŒì„± â†’ í…ìŠ¤íŠ¸)
    â†“
LLM ë¶„ì„ (í…ìŠ¤íŠ¸ â†’ ì»¨í…ìŠ¤íŠ¸)
    â†“
ê²°ê³¼ ì €ì¥ (transcriptions/ í´ë”)
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1ë‹¨ê³„: í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜

```bash
# Whisper ì´ë¯¸ ì„¤ì¹˜ë¨ (`.venv/bin/python3`ì—)

# sox ì„¤ì¹˜ (ë…¹ìŒìš©)
brew install sox

# Ollama ì„¤ì¹˜ (LLMìš©)
# https://ollama.aiì—ì„œ ë‹¤ìš´ë¡œë“œ
```

### 2ë‹¨ê³„: Ollama ì‹¤í–‰

```bash
# í„°ë¯¸ë„ 1: Ollama ì„œë²„ ì‹œì‘
ollama serve

# í„°ë¯¸ë„ 2: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì„ íƒì‚¬í•­)
ollama pull mistral
ollama pull neural-chat
```

### 3ë‹¨ê³„: Python ì½”ë“œ ì‹¤í–‰

```bash
# í„°ë¯¸ë„ 3
cd /Users/jangjun-yong/Desktop/jongf1

# ì˜ˆì œ 1: ë‹¨ìˆœ ë³€í™˜
python3 voice_analyzer.py

# ë˜ëŠ” ì˜ˆì œ í”„ë¡œê·¸ë¨
python3 voice_example.py interactive
```

---

## ğŸ¯ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë³„ ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸

### ì‹œë‚˜ë¦¬ì˜¤ 1: íšŒì˜ ê¸°ë¡

```python
meeting_prompt = """ë‹¹ì‹ ì€ íšŒì˜ ê¸°ë¡ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒì„ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
{
  "meeting_topic": "íšŒì˜ ì£¼ì œ",
  "key_decisions": ["ê²°ì •ì‚¬í•­ 1", "ê²°ì •ì‚¬í•­ 2"],
  "action_items": [
    {
      "task": "í• ì¼",
      "owner": "ë‹´ë‹¹ì",
      "deadline": "ë§ˆê°ì¼"
    }
  ]
}"""

analyzer = VoiceAnalyzer()
result = analyzer.transcribe_and_analyze(duration=10, system_prompt=meeting_prompt)
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ê³ ê° ì§€ì›

```python
support_prompt = """ë‹¹ì‹ ì€ ê³ ê° ì§€ì› ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
{
  "issue_type": "ë¬¸ì œ ìœ í˜• (ê¸°ìˆ /ê²°ì œ/ê¸°íƒ€)",
  "priority": "ìš°ì„ ìˆœìœ„ (ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ)",
  "sentiment": "ê³ ê° ê°ì • (ê¸ì •/ì¤‘ë¦½/ë¶€ì •)",
  "suggested_solution": "ì œì•ˆ í•´ê²°ì±…"
}"""

analyzer = VoiceAnalyzer()
result = analyzer.transcribe_and_analyze(duration=15, system_prompt=support_prompt)
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: í•™ìŠµ ê°•ì˜

```python
lecture_prompt = """ë‹¹ì‹ ì€ í•™ìŠµ ê°•ì˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
{
  "main_topics": ["ì£¼ì œ 1", "ì£¼ì œ 2"],
  "key_concepts": ["ê°œë… 1", "ê°œë… 2"],
  "learning_objectives": ["ëª©í‘œ 1", "ëª©í‘œ 2"],
  "difficulty_level": "ë‚œì´ë„ (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰)"
}"""
```

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
jongf1/
â”œâ”€â”€ voice_analyzer.py          # í•µì‹¬ ëª¨ë“ˆ (ì„í¬íŠ¸í•˜ì—¬ ì‚¬ìš©)
â”œâ”€â”€ voice_example.py           # ì‚¬ìš© ì˜ˆì œ
â”œâ”€â”€ voice_monitor.py           # ìë™ ëª¨ë‹ˆí„°ë§ìš© (ì°¸ê³ ìš©)
â”œâ”€â”€ api_server.py              # REST APIìš© (ì°¸ê³ ìš©)
â”œâ”€â”€ whisper_service.py         # Whisper ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ recordings/                # ì„ì‹œ ë…¹ìŒ íŒŒì¼ (ìë™ ì •ë¦¬)
â””â”€â”€ transcriptions/            # ê²°ê³¼ ì €ì¥
    â””â”€â”€ 2026-01-21/
        â”œâ”€â”€ transcriptions.json       # ëª¨ë“  ê²°ê³¼ (ë°°ì—´)
        â”œâ”€â”€ latest.json              # ìµœì‹  ê²°ê³¼
        â””â”€â”€ 2026-01-21T11-26-30-123.json  # ê°œë³„ ê²°ê³¼
```

---

## ğŸ”Œ ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ê³¼ ì—°ë™

### Pythonì—ì„œ ì‚¬ìš©

```python
from voice_analyzer import VoiceAnalyzer

# í•„ìš”í•œ ì‹œì ì— í˜¸ì¶œ
analyzer = VoiceAnalyzer()
result = analyzer.transcribe_and_analyze(duration=10)

# ë¶„ì„ ê²°ê³¼ í™œìš©
if result['success']:
    text = result['transcribed_text']
    analysis = result['analysis']
    
    # ì˜ˆ: ê°ì •ì´ ë¶€ì •ì ì´ë©´ ê²½ê³ 
    if analysis.get('sentiment') == 'ë¶€ì •':
        print("âš ï¸  ë¶€ì •ì ì¸ í”¼ë“œë°± ê°ì§€!")
```

### íŒŒì¼ ê¸°ë°˜ ì—°ë™

```python
import json
from pathlib import Path

# ìµœì‹  ê²°ê³¼ ì½ê¸°
latest_file = Path("transcriptions/2026-01-21/latest.json")
with open(latest_file) as f:
    result = json.load(f)
    print(result['analysis'])
```

### Shell/Command Line ì—°ë™

```bash
# Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í›„ ê²°ê³¼ ì½ê¸°
python3 voice_example.py 1 && \
cat transcriptions/*/latest.json | jq '.analysis'
```

---

## ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: "LLM ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŒ"

**í•´ê²°:**
```bash
# Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
ollama serve

# ë˜ëŠ” Ollama ì„¤ì • ë³€ê²½ í•„ìš”
OLLAMA_HOST=localhost:11434 ollama serve
```

### ë¬¸ì œ 2: "ë…¹ìŒ ì˜¤ë¥˜"

**í•´ê²°:**
```bash
# sox ì„¤ì¹˜ í™•ì¸
which sox

# ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìœ¼ë©´
brew install sox
```

### ë¬¸ì œ 3: "ë³€í™˜ ì‹¤íŒ¨ (No module named 'whisper')"

**í•´ê²°:**
```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” í™•ì¸
source /Users/jangjun-yong/Desktop/jongf1/.venv/bin/activate
pip list | grep whisper
```

---

## ğŸ“Š ê²°ê³¼ ì˜ˆì‹œ

```json
{
  "success": true,
  "timestamp": "2026-01-21T11:26:30.123Z",
  "transcribed_text": "ì•ˆë…•í•˜ì„¸ìš” ì €ëŠ” ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•˜ê³  ìˆìŠµë‹ˆë‹¤",
  "analysis": {
    "intent": "ì •ë³´ ì œê³µ",
    "entities": ["ìŒì„± ì¸ì‹", "ì‹œìŠ¤í…œ"],
    "sentiment": "ê¸ì •",
    "summary": "ì‚¬ìš©ìê°€ ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰ ì¤‘",
    "action": "ë¶„ì„ ì™„ë£Œ"
  },
  "audio_file": "/Users/jangjun-yong/Desktop/jongf1/recordings/audio_20260121_112630_123.wav"
}
```

---

## ğŸ’¡ íŒ

1. **ë¹„ìš© ì ˆê°**: ë¡œì»¬ LLM(Mistral, Neural Chat) ì‚¬ìš©ìœ¼ë¡œ API ë¹„ìš© 0ì›
2. **í”„ë¼ì´ë²„ì‹œ**: ëª¨ë“  ë°ì´í„°ê°€ ë¡œì»¬ì—ì„œ ì²˜ë¦¬ë¨
3. **ì†ë„**: GPU ìˆëŠ” Macì—ì„œ ë§¤ìš° ë¹ ë¦„ (Apple Silicon ìµœì í™”)
4. **í™•ì¥ì„±**: `voice_analyzer.py`ë¥¼ ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì— ì„í¬íŠ¸ ê°€ëŠ¥

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

1. **ì»¤ìŠ¤í…€ LLM ëª¨ë¸**: Ollamaì— ë‹¤ë¥¸ ëª¨ë¸ ì¶”ê°€
2. **ê²°ê³¼ ë°ì´í„°ë² ì´ìŠ¤**: ë¶„ì„ ê²°ê³¼ë¥¼ PostgreSQLì— ì €ì¥
3. **ëŒ€ì‹œë³´ë“œ**: ì‹œê°í™” ë° ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•
4. **API ë˜í•‘**: FastAPIë¡œ REST API êµ¬ì¶•
