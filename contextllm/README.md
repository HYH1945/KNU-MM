# ğŸ¤ ë¡œì»¬ Whisper + LLM ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œ

**macOSì—ì„œ ë¡œì»¬ AIë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ë° ìƒí™© ë¶„ì„ ì‹œìŠ¤í…œ**

[![Python 3.10.19](https://img.shields.io/badge/Python-3.10.19-3776ab?logo=python)](https://www.python.org/downloads/release/python-31019/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> ğŸ” **ì™„ì „ ë¡œì»¬ ì‹¤í–‰** - ëª¨ë“  ë°ì´í„°ê°€ ë‹¹ì‹ ì˜ ì»´í“¨í„°ì—ì„œë§Œ ì²˜ë¦¬ë¨  
> ğŸš€ **í”„ë¼ì´ë¹— + ë¹ ë¦„** - ì™¸ë¶€ API ë¶ˆí•„ìš”  
> ğŸ‡°ğŸ‡· **í•œêµ­ì–´ ì™„ë²½ ì§€ì›** - í•œêµ­ì–´ ë¬¸ë§¥ ë¶„ì„ ìµœì í™”  

---

## ğŸ“‹ ëª©ì°¨

1. [í”„ë¡œì íŠ¸ ì†Œê°œ](#í”„ë¡œì íŠ¸-ì†Œê°œ)
2. [í•„ìˆ˜ ì„¤ì¹˜ ìš”êµ¬ì‚¬í•­](#í•„ìˆ˜-ì„¤ì¹˜-ìš”êµ¬ì‚¬í•­)
3. [OSë³„ ì„¤ì¹˜ ê°€ì´ë“œ](#-osë³„-ì„¤ì¹˜-ê°€ì´ë“œ)
4. [ì„¤ì¹˜ ë°©ë²•](#ì„¤ì¹˜-ë°©ë²•)
5. [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
6. [í”„ë¡œì íŠ¸ êµ¬ì¡°](#í”„ë¡œì íŠ¸-êµ¬ì¡°)
7. [ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì— ì´ì‹í•˜ê¸°](#ë‹¤ë¥¸-í”„ë¡œì íŠ¸ì—-ì´ì‹í•˜ê¸°)
8. [ìì£¼ ë¬»ëŠ” ì§ˆë¬¸](#ìì£¼-ë¬»ëŠ”-ì§ˆë¬¸)

---

## í”„ë¡œì íŠ¸ ì†Œê°œ

ì´ í”„ë¡œì íŠ¸ëŠ” **ë¡œì»¬ AI ëª¨ë¸**ì„ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸ì‹í•˜ê³  ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥

| ê¸°ëŠ¥ | ì„¤ëª… | ê¸°ìˆ  |
|------|------|------|
| ğŸµ **ìŒì„± ì¸ì‹** | ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ | OpenAI Whisper |
| ğŸ¤– **ì»¨í…ìŠ¤íŠ¸ ë¶„ì„** | í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìƒí™© íŒŒì•… | Ollama + LLM |
| ğŸ’¾ **ìë™ ì €ì¥** | ëª¨ë“  ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥ | Python |
| ğŸ”Š **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§** | ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§ | Threading |
| ğŸ“¡ **REST API** | ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ê³¼ í†µí•© ê°€ëŠ¥ | Flask |

### ì²˜ë¦¬ íë¦„

```
ğŸ¤ ìŒì„± ë…¹ìŒ
    â†“
ğŸ“ Whisper â†’ í…ìŠ¤íŠ¸ ë³€í™˜
    â†“
ğŸ§  Ollama LLM â†’ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
    â†“
ğŸ’¾ JSON íŒŒì¼ì— ì €ì¥
    â†“
ğŸ“Š ê²°ê³¼ í™•ì¸
```

---

## í•„ìˆ˜ ì„¤ì¹˜ ìš”êµ¬ì‚¬í•­

### 1. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **OS**: macOS (M1/M2/Intel)
- **Python**: 3.10.19 (ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ ê³ ì •)
- **RAM**: ìµœì†Œ 8GB (ê¶Œì¥ 16GB)
- **ë””ìŠ¤í¬**: 10GB ì—¬ìœ  ê³µê°„
- **ì¸í„°ë„·**: ì´ˆê¸° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì—ë§Œ í•„ìš”

### 2. ì™¸ë¶€ ë„êµ¬ ì„¤ì¹˜

#### ğŸ˜ Ollama (í•„ìˆ˜)

OllamaëŠ” LLMì„ ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

```bash
# macOSì— ì„¤ì¹˜
brew install ollama

# ë˜ëŠ” ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ ë‹¤ìš´ë¡œë“œ
# https://ollama.ai
```

**Ollama í™•ì¸:**
```bash
ollama --version
# ollama version is 0.x.x
```

#### ğŸ”Š Sox (ìŒì„± ë…¹ìŒìš©)

```bash
# macOSì— ì„¤ì¹˜
brew install sox
```

**Sox í™•ì¸:**
```bash
sox --version
# sox: SoX v14.4.2
```

### 3. Python í™˜ê²½ ì„¤ì •

ì´ í”„ë¡œì íŠ¸ëŠ” **Python 3.10.19**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

```bash
# í˜„ì¬ Python ë²„ì „ í™•ì¸
python3 --version
# Python 3.10.19

# Python 3.10ì´ ì—†ëŠ” ê²½ìš° ì„¤ì¹˜
brew install python@3.10
```

---

## ğŸ–¥ï¸ OSë³„ ì„¤ì¹˜ ê°€ì´ë“œ

### macOS (ê¶Œì¥ - ë³¸ ê°€ì´ë“œ ê¸°ë³¸)

ìœ„ì˜ ê¸°ë³¸ ì„¤ì¹˜ ë°©ë²•ì„ ë”°ë¥´ë©´ ë©ë‹ˆë‹¤.

```bash
# íŒ¨í‚¤ì§€ ì„¤ì¹˜
brew install ollama sox python@3.10

# Homebrew ê²½ë¡œ í™•ì¸
/opt/homebrew/bin/python3.10 --version
```

### ğŸªŸ Windows

Windowsì—ì„œ ì„¤ì¹˜í•˜ë ¤ë©´ ë‹¤ìŒì„ ìˆ˜ì •í•˜ì„¸ìš”:

#### 1. Ollama ì„¤ì¹˜
- https://ollama.ai ì—ì„œ Windows ë²„ì „ ë‹¤ìš´ë¡œë“œ
- ì„¤ì¹˜ í›„ PowerShell ë˜ëŠ” CMDì—ì„œ:
  ```cmd
  ollama --version
  ollama serve
  ```

#### 2. Sox ì„¤ì¹˜
Windowsì—ì„œëŠ” SoX ëŒ€ì‹  **PyAudio** ë˜ëŠ” **sounddevice** ì‚¬ìš©:

```bash
# ì˜µì…˜ 1: PyAudio (ê¶Œì¥)
pip install pyaudio

# ì˜µì…˜ 2: sounddevice
pip install sounddevice
```

#### 3. Python ì„¤ì •
```bash
# Python 3.10 ì„¤ì¹˜ í›„
python --version
# Python 3.10.19

# ê°€ìƒ í™˜ê²½ ìƒì„± (macOSì™€ ë™ì¼)
python -m venv .venv

# ê°€ìƒ í™˜ê²½ í™œì„±í™” (Windows)
.venv\Scripts\activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

#### 4. ìŒì„± ë…¹ìŒ ìˆ˜ì •
[voice_analyzer.py](voice_analyzer.py)ì—ì„œ `record_audio()` ë©”ì„œë“œë¥¼ ìˆ˜ì •:

```python
# macOS (ê¸°ì¡´)
subprocess.run(['sox', '-d', output_file, ...])

# Windows (ìˆ˜ì •)
import sounddevice as sd
import scipy.io.wavfile as wavfile

def record_audio(self, duration=10, output_file=None):
    import sounddevice as sd
    import scipy.io.wavfile as wavfile
    
    sample_rate = 16000
    print(f"ğŸ¤ ë…¹ìŒ ì¤‘... ({duration}ì´ˆ)")
    
    recording = sd.rec(int(duration * sample_rate), 
                       samplerate=sample_rate, 
                       channels=1)
    sd.wait()
    
    wavfile.write(output_file, sample_rate, recording)
    print(f"âœ… ë…¹ìŒ ì™„ë£Œ: {output_file}")
    return output_file
```

#### 5. ì„¤ì • íŒŒì¼ ìˆ˜ì • (voice_analyzer.py)
```python
# macOS
VENV_PYTHON = "./.venv/bin/python3"

# Windows (ìˆ˜ì •)
import sys
VENV_PYTHON = ".\\venv\\Scripts\\python.exe"  # ë˜ëŠ” sys.executable
```

#### 6. ì‹¤í–‰
```bash
# PowerShell ë˜ëŠ” CMD
python voice_analyzer.py
```

**ì£¼ì˜:** Windowsì—ì„œëŠ” FFmpegë„ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
```bash
# Chocolatey ì‚¬ìš©
choco install ffmpeg

# ë˜ëŠ” ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ
# https://ffmpeg.org/download.html
```

### ğŸ§ Linux (Ubuntu/Debian)

Linuxì—ì„œ ì„¤ì¹˜í•˜ë ¤ë©´ ë‹¤ìŒì„ ìˆ˜ì •í•˜ì„¸ìš”:

#### 1. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install -y python3.10 python3.10-venv sox ffmpeg libsndfile1

# Ollama ì„¤ì¹˜
curl -fsSL https://ollama.ai/install.sh | sh
```

#### 2. Ollama ì‹¤í–‰
```bash
# ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤ë¡œ ì‹¤í–‰
sudo systemctl start ollama
sudo systemctl status ollama

# ë˜ëŠ” ìˆ˜ë™ ì‹¤í–‰
ollama serve
```

#### 3. Python ê°€ìƒ í™˜ê²½ ìƒì„±
```bash
# Python 3.10ìœ¼ë¡œ venv ìƒì„±
python3.10 -m venv .venv

# í™œì„±í™”
source .venv/bin/activate

# í™•ì¸
python --version
# Python 3.10.19
```

#### 4. íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install -r requirements.txt

# ìŒì„± ì²˜ë¦¬ ì¶”ê°€ íŒ¨í‚¤ì§€
pip install soundfile libsndfile
```

#### 5. ìŒì„± ë…¹ìŒ ìˆ˜ì • (ì„ íƒì‚¬í•­)
Linuxì—ì„œë„ Soxê°€ ê¸°ë³¸ì ìœ¼ë¡œ ì‘ë™í•˜ë¯€ë¡œ, ì¶”ê°€ ìˆ˜ì •ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤.

#### 6. ì‹¤í–‰
```bash
source .venv/bin/activate
python3 voice_analyzer.py
```

**ì•Œë¦¼:** ê¶Œí•œ ë¬¸ì œ ë°œìƒ ì‹œ:
```bash
# ë§ˆì´í¬ ê¶Œí•œ í™•ì¸
groups $USER | grep -q audio || sudo usermod -aG audio $USER

# ì¬ë¶€íŒ… í•„ìš”í•  ìˆ˜ ìˆìŒ
```

### ğŸ Apple Silicon vs Intel Mac

#### Intel Mac (x86_64)
```bash
# ê¸°ë³¸ Homebrew ì‚¬ìš© ê°€ëŠ¥
brew install python@3.10 ollama sox

python3.10 -m venv .venv
source .venv/bin/activate
```

#### Apple Silicon Mac (M1/M2/M3, arm64)
```bash
# Apple Silicon ìµœì í™” ë²„ì „ ì„¤ì¹˜
brew install python@3.10 ollama sox

# Rosetta 2 í˜¸í™˜ì„± í™•ì¸
arch
# arm64

# ê°€ìƒ í™˜ê²½ ìƒì„± (ìë™ arm64 ì‚¬ìš©)
python3.10 -m venv .venv
source .venv/bin/activate
```

**ë¬¸ì œ ë°œìƒ ì‹œ:**
```bash
# Rosetta 2 í™˜ê²½ì—ì„œ ì„¤ì¹˜ (í•„ìš”í•œ ê²½ìš°)
arch -x86_64 /bin/bash
arch -x86_64 python3.10 -m venv .venv
```

---

## ì„¤ì¹˜ ë°©ë²•

### ğŸ“¥ Step 1: ì €ì¥ì†Œ í´ë¡ 

```bash
# ì›í•˜ëŠ” ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd ~/Desktop

# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/YOUR_USERNAME/contextllm.git
cd contextllm
```

### ğŸ Step 2: Python ê°€ìƒ í™˜ê²½ ìƒì„±

```bash
# Python 3.10ìœ¼ë¡œ ê°€ìƒ í™˜ê²½ ìƒì„±
/opt/homebrew/bin/python3.10 -m venv .venv

# ê°€ìƒ í™˜ê²½ í™œì„±í™”
source .venv/bin/activate

# í™•ì¸
python --version
# Python 3.10.19
```

### ğŸ“¦ Step 3: íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# ê°€ìƒ í™˜ê²½ í™œì„±í™” ìƒíƒœì—ì„œ
pip install -r requirements.txt

# ì„¤ì¹˜ í™•ì¸ (ì•½ 2-3ë¶„ ì†Œìš”)
pip list | grep -E "whisper|torch|numpy"
```

### ğŸ¤– Step 4: Ollama ëª¨ë¸ ì¤€ë¹„

```bash
# í„°ë¯¸ë„ 1: Ollama ì„œë²„ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)
ollama serve

# í„°ë¯¸ë„ 2: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì²« ì‹¤í–‰ ì‹œì—ë§Œ)
ollama pull mistral        # ì•½ 4GB
# ë˜ëŠ”
ollama pull neural-chat    # ë” ë¹ ë¥¸ ì‘ë‹µ

# ëª¨ë¸ í™•ì¸
ollama list
```

**ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ:**

| ëª¨ë¸ | í¬ê¸° | ì†ë„ | í’ˆì§ˆ | ë©”ëª¨ë¦¬ |
|------|------|------|------|--------|
| mistral | 4GB | ì¤‘ê°„ | ë†’ìŒ | 8GB |
| neural-chat | 3.9GB | ë¹ ë¦„ | ì¤‘ê°„ | 8GB |
| openchat | 3.8GB | ë¹ ë¦„ | ì¤‘ê°„ | 8GB |

---

## ì‚¬ìš© ë°©ë²•

### ğŸ™ï¸ ë°©ë²• 1: ê¸°ë³¸ ìŒì„± ë¶„ì„ (ì¶”ì²œ)

```bash
# ê°€ìƒ í™˜ê²½ í™œì„±í™”
source .venv/bin/activate

# ìŒì„± ì¸ì‹ + LLM ë¶„ì„
python3 voice_analyzer.py

# ì¶œë ¥ ì˜ˆ:
# ğŸ¤ ë…¹ìŒ ì¤‘... (10ì´ˆ)
# âœ… ë…¹ìŒ ì™„ë£Œ
# ğŸ“ í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...
# ğŸ§  LLM ë¶„ì„ ì¤‘...
# ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ
```

**ì¸í„°ë™í‹°ë¸Œ ì‚¬ìš©:**

```python
from voice_analyzer import VoiceAnalyzer

analyzer = VoiceAnalyzer()

# ğŸ¤ ë°©ì‹ 1: ê³ ì • ì‹œê°„ ë…¹ìŒ (15ì´ˆ)
result = analyzer.transcribe_and_analyze(duration=15)

print("ğŸ¤ ìŒì„±:", result['transcribed_text'])
print("ğŸ“Š ë¶„ì„ ê²°ê³¼:")
print(f"  - ìƒí™©: {result['analysis']['situation']}")
print(f"  - ê°ì •: {result['analysis']['emotional_state']}")
print(f"  - ìœ„ê¸‰ë„: {result['analysis']['urgency']}")
```

#### ğŸ¤ íŠ¹ë³„ ê¸°ëŠ¥: ë¬´í•œ ë…¹ìŒ (Enterë¡œ ì¢…ë£Œ)

ê¸°ìˆ  í•œê³„: **ì§„ì •í•œ ì‹¤ì‹œê°„ ìŒì„± ì²˜ë¦¬ëŠ” ë¶ˆê°€ëŠ¥**í•©ë‹ˆë‹¤. ì™œëƒí•˜ë©´:
- WhisperëŠ” ì™„ì„±ëœ ìŒì„± íŒŒì¼ì´ í•„ìš”
- ì‹¤ì‹œê°„ ì²˜ë¦¬í•˜ë ¤ë©´ ë³„ë„ì˜ ìŠ¤íŠ¸ë¦¬ë° ìŒì„±ì¸ì‹ API í•„ìš” (Google Speech-to-Text, Azure Speech Services ë“±)

ëŒ€ì‹  **Enter í‚¤ë¡œ ì–¸ì œë“  ë…¹ìŒì„ ì¤‘ë‹¨í•  ìˆ˜ ìˆëŠ” ë¬´í•œ ë…¹ìŒ ëª¨ë“œ**ë¥¼ ì œê³µí•©ë‹ˆë‹¤:

```python
# ğŸ’¡ Enter í‚¤ê¹Œì§€ ë¬´í•œ ë…¹ìŒ (10ì´ˆ ì´ìƒ í•„ìš” ì‹œ)
result = analyzer.transcribe_and_analyze(duration=None)
# ğŸ¤ ë¬´í•œ ë…¹ìŒ ì‹œì‘... (Enter í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ)
# [ì‚¬ìš©ìê°€ ë§í•¨...]
# [Enter í‚¤ ëˆ„ë¦„]
# â¹ï¸  ë…¹ìŒ ì¤‘ì§€ ì¤‘...
# âœ… ë…¹ìŒ ì™„ë£Œ
```

#### ğŸš€ ê±°ì˜ ì‹¤ì‹œê°„ ì²˜ë¦¬: 10ì´ˆ ê°„ê²© ë°˜ë³µ ì‹¤í–‰ (ì‹ ê¸°ëŠ¥!)

ìŒì„±ì´ ì…ë ¥ë  ë•Œë§ˆë‹¤ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ë ¤ë©´, **10ì´ˆ ê°„ê²©ìœ¼ë¡œ ë°˜ë³µ ì‹¤í–‰**í•˜ì„¸ìš”:

```python
from voice_analyzer import VoiceAnalyzer

analyzer = VoiceAnalyzer()

# ìˆœì°¨ ì²˜ë¦¬: 10ì´ˆ ê°„ê²©ìœ¼ë¡œ ë¬´í•œ ë°˜ë³µ (ê±°ì˜ ì‹¤ì‹œê°„)
analyzer.run_continuously(interval=10)

# ë³‘ë ¬ ì²˜ë¦¬: ì§„ì •í•œ ì‹¤ì‹œê°„ (NEW!)
analyzer.run_parallel_realtime(interval=10)
```

**ì‹¤í–‰ ê²°ê³¼ (ë³‘ë ¬ ì²˜ë¦¬ - ì§„ì •í•œ ì‹¤ì‹œê°„):**
```
============================================================
âš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ì§„ì •í•œ ì‹¤ì‹œê°„!)
============================================================

[ë…¹ìŒ 1ì°¨] ì‹œê°„: 11:55:00
  ğŸ¤ 10ì´ˆ ë…¹ìŒ ì¤‘...

[ë¶„ì„ 1ì°¨] ì‹œê°„: 11:55:05
  ğŸ“ Whisper ë³€í™˜ ì¤‘...
  âœ… ìŒì„±: "ì•ˆë…•í•˜ì„¸ìš” ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”"
  ğŸš¨ ìœ„ê¸‰ë„: ë‚®ìŒ
  ğŸ˜Š ê°ì •: ê¸ì •

[ë…¹ìŒ 2ì°¨] ì‹œê°„: 11:55:10 (ë™ì‹œì— ì§„í–‰!)
  ğŸ¤ 10ì´ˆ ë…¹ìŒ ì¤‘...

[ë¶„ì„ 2ì°¨] ì‹œê°„: 11:55:15
  ğŸ“ Whisper ë³€í™˜ ì¤‘...
  âœ… ìŒì„±: "ë„ì™€ì£¼ì„¸ìš” ì§€ê¸ˆ ê¸´ê¸‰ìƒí™©ì…ë‹ˆë‹¤"
  ğŸš¨ ìœ„ê¸‰ë„: ê¸´ê¸‰
  ğŸ˜Š ê°ì •: ë¶€ì •
```

**í…ŒìŠ¤íŠ¸ìš© ì œí•œ ë°˜ë³µ:**

```python
# ìˆœì°¨ ì²˜ë¦¬: 5íšŒë§Œ ë°˜ë³µ
analyzer.run_continuously(interval=10, max_iterations=5)

# ë³‘ë ¬ ì²˜ë¦¬: 5íšŒë§Œ ë°˜ë³µ (ê¶Œì¥)
analyzer.run_parallel_realtime(interval=10, max_iterations=5)

# ë˜ëŠ” ëª…ë ¹ì¤„ì—ì„œ
python voice_analyzer.py
# ì„ íƒ: 4 (ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë‹ˆí„°ë§ - ì§„ì •í•œ ì‹¤ì‹œê°„)
# ë°˜ë³µ íšŸìˆ˜: 1 (ë¬´í•œ ë°˜ë³µ)
```

**6ê°€ì§€ ì‚¬ìš© ëª¨ë“œ:**

| ëª¨ë“œ | ì½”ë“œ | íŠ¹ì§• | ì§€ì—°ì‹œê°„ |
|------|------|------|---------|
| ê³ ì • ì‹œê°„ | `duration=10` | ì •í™•íˆ 10ì´ˆ ë…¹ìŒ | ì¦‰ì‹œ |
| ë¬´í•œ ë…¹ìŒ | `duration=None` | Enter í‚¤ ëˆŒ ë•Œê¹Œì§€ | ì¦‰ì‹œ |
| ìˆœì°¨ ì²˜ë¦¬ | `run_continuously(interval=10)` | ê±°ì˜ ì‹¤ì‹œê°„ | ~15-20ì´ˆ |
| **ë³‘ë ¬ ì²˜ë¦¬ â­** | **`run_parallel_realtime(interval=10)`** | **ì§„ì •í•œ ì‹¤ì‹œê°„ (ë³‘ë ¬)** | **~10ì´ˆ** |
| í…ŒìŠ¤íŠ¸ (ìˆœì°¨) | `run_continuously(max_iterations=5)` | ìˆœì°¨ ì œí•œ ë°˜ë³µ | ~15-20ì´ˆ |
| í…ŒìŠ¤íŠ¸ (ë³‘ë ¬) | `run_parallel_realtime(max_iterations=5)` | ë³‘ë ¬ ì œí•œ ë°˜ë³µ | ~10ì´ˆ |

**ìˆœì°¨ vs ë³‘ë ¬ ì²˜ë¦¬ ë¹„êµ:**

```
ğŸ”´ ìˆœì°¨ ì²˜ë¦¬ (ê¸°ì¡´)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ë…¹ìŒ(10s) â†’ ë³€í™˜(2-5s) â†’ ë¶„ì„(2-3s) â†’ ë…¹ìŒ(10s) â†’ ...
ì´: 15-20ì´ˆ ê°„ê²©

ğŸŸ¢ ë³‘ë ¬ ì²˜ë¦¬ (ì‹ ê·œ) â­
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ìŠ¤ë ˆë“œ1: ë…¹ìŒ1 â†’ ë…¹ìŒ2 â†’ ë…¹ìŒ3 â†’ ...
ìŠ¤ë ˆë“œ2:      ë³€í™˜1+ë¶„ì„1 â†’ ë³€í™˜2+ë¶„ì„2 â†’ ...

ê²°ê³¼: ì•½ 10ì´ˆ ê°„ê²© (ì§„ì •í•œ ê±°ì˜ ì‹¤ì‹œê°„!)
```

**ê±°ì˜ ì‹¤ì‹œê°„ ì²˜ë¦¬ì˜ íŠ¹ì§•:**

âœ… **ë³‘ë ¬ ì²˜ë¦¬ì˜ ì¥ì :**
- âš¡ ì•½ 10ì´ˆ ê°„ê²© (ë¹ ë¦„!)
- ğŸ¤ ë…¹ìŒê³¼ ë¶„ì„ ë™ì‹œ ì§„í–‰
- ì§„ì •í•œ ê±°ì˜ ì‹¤ì‹œê°„!
- ìœ„ê¸‰ë„ë³„ ì‹¤ì‹œê°„ ì•Œë¦¼ ê°€ëŠ¥
- CPU íš¨ìœ¨ì  (ì§€ì—°ì‹œê°„ ë‹¨ì¶•)

âŒ **ì œì•½:**
- ì •í™•í•œ ì‹¤ì‹œê°„ì€ ì•„ë‹˜ (10ì´ˆ ì§€ì—°)
- CPU/ë©”ëª¨ë¦¬ ì‚¬ìš© (2ê°œ ìŠ¤ë ˆë“œ)

- Ollama ì„œë²„ í•­ìƒ ì‹¤í–‰ í•„ìš”

### ğŸš€ ë°©ë²• 2: REST API ì„œë²„ë¡œ ì‹¤í–‰

ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ HTTP ìš”ì²­ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•©ë‹ˆë‹¤.

```bash
# API ì„œë²„ ì‹œì‘
python3 api_server.py

# ì„œë²„ëŠ” http://localhost:5000 ì—ì„œ ì‹¤í–‰ë¨
```

**Pythonì—ì„œ API ì‚¬ìš©:**

```python
import requests

response = requests.post('http://localhost:5000/api/transcribe', 
    json={'audio_file': '/path/to/audio.wav'})
result = response.json()
print(result['text'])
```

**JavaScript/Node.jsì—ì„œ API ì‚¬ìš©:**

```javascript
const response = await fetch('http://localhost:5000/api/transcribe', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({audio_file: '/path/to/audio.wav'})
});
const result = await response.json();
console.log(result.text);
```

### ğŸ”„ ë°©ë²• 3: ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§

```bash
# ì§€ì†ì ìœ¼ë¡œ ìŒì„±ì„ ëª¨ë‹ˆí„°ë§ (Ctrl+Cë¡œ ì¢…ë£Œ)
python3 voice_monitor.py
```

### ğŸ“Š ê²°ê³¼ í™•ì¸

ëª¨ë“  ê²°ê³¼ëŠ” `transcriptions/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤.

```
transcriptions/
â”œâ”€â”€ 2026-01-22/
â”‚   â”œâ”€â”€ transcriptions.json    # í•´ë‹¹ ë‚ ì§œ ëª¨ë“  ê²°ê³¼ (ë°°ì—´)
â”‚   â”œâ”€â”€ latest.json            # ìµœì‹  ê²°ê³¼ (ë®ì–´ì“°ê¸°)
â”‚   â”œâ”€â”€ transcriptions.txt     # í…ìŠ¤íŠ¸ í˜•ì‹ ë¡œê·¸
â”‚   â””â”€â”€ 2026-01-22T10-30-45Z.json  # ê°œë³„ ê²°ê³¼
```

**ê²°ê³¼ êµ¬ì¡°:**

```json
{
  "timestamp": "2026-01-22T10:30:45Z",
  "transcribed_text": "ì•ˆë…•í•˜ì„¸ìš”. ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”.",
  "analysis": {
    "context": "ì¼ìƒ ëŒ€í™”",
    "situation": "ì‚¬ìš©ìê°€ ë‚ ì”¨ì— ëŒ€í•´ ê¸ì •ì ìœ¼ë¡œ í‘œí˜„í•¨",
    "emotional_state": "ê¸ì •",
    "urgency": "ë‚®ìŒ"
  }
}
```

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
contextllm/
â”œâ”€â”€ README.md                      # ì´ íŒŒì¼
â”œâ”€â”€ requirements.txt               # Python íŒ¨í‚¤ì§€ ëª©ë¡ (Python 3.10.19ìš©)
â”‚
â”œâ”€â”€ ğŸ¤ í•µì‹¬ ëª¨ë“ˆ
â”œâ”€â”€ voice_analyzer.py              # ìŒì„± ì¸ì‹ + LLM ë¶„ì„ (ë©”ì¸)
â”œâ”€â”€ voice_example.py               # ì‚¬ìš© ì˜ˆì œ
â”œâ”€â”€ voice_monitor.py               # ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§
â”œâ”€â”€ whisper_service.py             # Whisper ë˜í¼
â”‚
â”œâ”€â”€ ğŸ“¡ API ì„œë²„
â”œâ”€â”€ api_server.py                  # REST API ì„œë²„ (Flask)
â”‚
â”œâ”€â”€ ğŸ“ ë¬¸ì„œ
â”œâ”€â”€ SETUP_GUIDE.md                 # ìƒì„¸ ì„¤ì • ê°€ì´ë“œ
â”œâ”€â”€ GITHUB_SETUP.md                # GitHub ì—…ë¡œë“œ ê°€ì´ë“œ
â”œâ”€â”€ OLLAMA_GUIDE.md                # Ollama ìƒì„¸ ê°€ì´ë“œ
â”œâ”€â”€ REAL_TEST_GUIDE.md             # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ
â”‚
â”œâ”€â”€ ğŸ§ª í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ test_ollama.py                 # Ollama ì—°ê²° í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_korean_analysis.py        # í•œêµ­ì–´ ë¶„ì„ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_real_analysis.py          # ì‹¤ì œ ìŒì„± ë¶„ì„ í…ŒìŠ¤íŠ¸
â”‚
â”œâ”€â”€ ğŸ“ ë””ë ‰í† ë¦¬
â”œâ”€â”€ .venv/                         # Python ê°€ìƒ í™˜ê²½ (ìë™ ìƒì„±)
â”œâ”€â”€ recordings/                    # ë…¹ìŒ íŒŒì¼ ì €ì¥ì†Œ
â”œâ”€â”€ transcriptions/                # ë¶„ì„ ê²°ê³¼ ì €ì¥ì†Œ
â””â”€â”€ src/                           # VS Code í™•ì¥ ì†ŒìŠ¤ (TypeScript)
    â””â”€â”€ extension.ts               # VS Code í”ŒëŸ¬ê·¸ì¸
```

### ì£¼ìš” íŒŒì¼ ì„¤ëª…

#### ğŸ¯ voice_analyzer.py (ë©”ì¸)

```python
class VoiceAnalyzer:
    """ìŒì„± ì¸ì‹ + LLM ë¶„ì„ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def record_audio(duration=10)
        # Soxë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± ë…¹ìŒ
    
    def transcribe(audio_file)
        # Whisperë¡œ ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜
    
    def analyze(text, system_prompt=None)
        # Ollama LLMìœ¼ë¡œ í…ìŠ¤íŠ¸ ë¶„ì„
    
    def transcribe_and_analyze(duration=10, system_prompt=None)
        # ë…¹ìŒ + ë³€í™˜ + ë¶„ì„ ì „ì²´ í”„ë¡œì„¸ìŠ¤
```

#### ğŸ“¡ api_server.py (REST API)

```python
# POST /api/transcribe - ìŒì„± íŒŒì¼ ë³€í™˜
response = requests.post('http://localhost:5000/api/transcribe',
    json={'audio_file': 'path/to/audio.wav'})

# POST /api/analyze - í…ìŠ¤íŠ¸ ë¶„ì„
response = requests.post('http://localhost:5000/api/analyze',
    json={'text': 'ë¶„ì„í•  í…ìŠ¤íŠ¸'})

# GET /api/status - ì„œë²„ ìƒíƒœ í™•ì¸
response = requests.get('http://localhost:5000/api/status')
```

---

## ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì— ì´ì‹í•˜ê¸°

### ğŸ”— ë°©ë²• 1: ëª¨ë“ˆë¡œ ì„í¬íŠ¸

ì´ í”„ë¡œì íŠ¸ë¥¼ ë‹¤ë¥¸ Python í”„ë¡œì íŠ¸ì—ì„œ ëª¨ë“ˆë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### 1ë‹¨ê³„: íŒŒì¼ ë³µì‚¬

```bash
# ë‹¹ì‹ ì˜ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd ~/Desktop/my_project

# contextllm íŒŒì¼ë“¤ì„ ë³µì‚¬
cp ~/Desktop/contextllm/voice_analyzer.py .
cp ~/Desktop/contextllm/whisper_service.py .
cp ~/Desktop/contextllm/requirements.txt ./requirements_whisper.txt
```

#### 2ë‹¨ê³„: íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# ê¸°ì¡´ requirements.txtì— ë³‘í•©
cat requirements_whisper.txt >> requirements.txt

# ì„¤ì¹˜
pip install -r requirements.txt
```

#### 3ë‹¨ê³„: ì½”ë“œì—ì„œ ì‚¬ìš©

```python
from voice_analyzer import VoiceAnalyzer

class MyApp:
    def __init__(self):
        self.analyzer = VoiceAnalyzer()
    
    def process_voice(self):
        result = self.analyzer.transcribe_and_analyze(duration=10)
        return result['analysis']

# ì‚¬ìš©
app = MyApp()
analysis = app.process_voice()
```

### ğŸŒ ë°©ë²• 2: REST APIë¡œ ì—°ê²°

ë³„ë„ì˜ ì„œë²„ë¡œ ì‹¤í–‰í•˜ê³  HTTPë¡œ í†µì‹ í•©ë‹ˆë‹¤.

#### 1ë‹¨ê³„: ì´ í”„ë¡œì íŠ¸ë¥¼ API ì„œë²„ë¡œ ì‹¤í–‰

```bash
cd ~/Desktop/contextllm
source .venv/bin/activate
python3 api_server.py
# API ì„œë²„ ì‹¤í–‰ ì¤‘... (http://localhost:5000)
```

#### 2ë‹¨ê³„: ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì—ì„œ API í˜¸ì¶œ

**Python:**

```python
import requests

class VoiceClient:
    def __init__(self, api_url="http://localhost:5000"):
        self.api_url = api_url
    
    def transcribe(self, audio_file):
        response = requests.post(
            f'{self.api_url}/api/transcribe',
            json={'audio_file': audio_file}
        )
        return response.json()
    
    def analyze(self, text):
        response = requests.post(
            f'{self.api_url}/api/analyze',
            json={'text': text}
        )
        return response.json()

# ì‚¬ìš©
client = VoiceClient()
result = client.transcribe('/path/to/audio.wav')
```

**Node.js/JavaScript:**

```javascript
class VoiceClient {
    constructor(apiUrl = 'http://localhost:5000') {
        this.apiUrl = apiUrl;
    }
    
    async transcribe(audioFile) {
        const response = await fetch(`${this.apiUrl}/api/transcribe`, {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({audio_file: audioFile})
        });
        return await response.json();
    }
    
    async analyze(text) {
        const response = await fetch(`${this.apiUrl}/api/analyze`, {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({text: text})
        });
        return await response.json();
    }
}

// ì‚¬ìš©
const client = new VoiceClient();
const result = await client.transcribe('/path/to/audio.wav');
```

### ğŸ“¦ ë°©ë²• 3: Docker ì»¨í…Œì´ë„ˆë¡œ ë°°í¬

```dockerfile
FROM python:3.10.19-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["python3", "api_server.py"]
```

**ë¹Œë“œ ë° ì‹¤í–‰:**

```bash
# ë¹Œë“œ
docker build -t voice-analyzer .

# ì‹¤í–‰
docker run -p 5000:5000 voice-analyzer
```

### ğŸ”§ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# .env íŒŒì¼ ë˜ëŠ” ì‹œìŠ¤í…œ í™˜ê²½ ë³€ìˆ˜
export OLLAMA_MODEL=mistral
export WHISPER_MODEL=base
export API_PORT=5000
export RECORDING_DURATION=10
```

**Python ì½”ë“œì—ì„œ ì‚¬ìš©:**

```python
import os

OLLAMA_MODEL = os.getenv('OLLAMA_MODEL', 'mistral')
WHISPER_MODEL = os.getenv('WHISPER_MODEL', 'base')
API_PORT = int(os.getenv('API_PORT', 5000))
```

---

## ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)

### Q1: ìŒì„± ë…¹ìŒì´ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

**A:** Soxê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.

```bash
# Sox ì„¤ì¹˜
brew install sox

# í™•ì¸
sox --version

# ë§ˆì´í¬ í…ŒìŠ¤íŠ¸
sox -d test.wav
# 3ì´ˆê°„ ë…¹ìŒ í›„ Ctrl+Cë¡œ ì¢…ë£Œ
play test.wav  # ì¬ìƒ í…ŒìŠ¤íŠ¸
```

### Q2: Ollama ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.

**A:** Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

```bash
# ìƒˆ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰
ollama serve

# ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ í…ŒìŠ¤íŠ¸
curl http://localhost:11434/api/tags
```

### Q3: "No module named 'whisper'" ì˜¤ë¥˜

**A:** ê°€ìƒ í™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ì„ ê°€ëŠ¥ì„±ì…ë‹ˆë‹¤.

```bash
# ê°€ìƒ í™˜ê²½ í™œì„±í™” í™•ì¸
which python
# /Users/.../.venv/bin/python ì¸ì§€ í™•ì¸

# ì¬ì„¤ì¹˜
source .venv/bin/activate
pip install -r requirements.txt
```

### Q4: Python 3.10.19ì´ ì—†ìŠµë‹ˆë‹¤.

**A:** Homebrewë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.

```bash
brew install python@3.10

# í™•ì¸
/opt/homebrew/bin/python3.10 --version
# Python 3.10.19
```

### Q5: í•œêµ­ì–´ê°€ ì œëŒ€ë¡œ ì¸ì‹ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

**A:** Whisperì˜ ì–¸ì–´ ì„¤ì •ì„ ëª…ì‹œí•˜ì„¸ìš”.

```python
from voice_analyzer import VoiceAnalyzer

analyzer = VoiceAnalyzer()

# whisper_service.pyì—ì„œ ì–¸ì–´ ì„¤ì •
# --language ko ì˜µì…˜ ì¶”ê°€
result = analyzer.transcribe_and_analyze(
    duration=10,
    language='ko'  # í•œêµ­ì–´ ì§€ì •
)
```

### Q6: ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.

**A:** ë” ê°€ë²¼ìš´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê±°ë‚˜ RAMì„ ì¦ì„¤í•˜ì„¸ìš”.

```bash
# ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
ollama pull neural-chat  # Mistralë³´ë‹¤ ê°€ë²¼ì›€

# ë˜ëŠ” venv ì„¤ì •ì—ì„œ ëª¨ë¸ ë©”ëª¨ë¦¬ ì œí•œ
export OLLAMA_NUM_THREAD=4  # CPU ìŠ¤ë ˆë“œ ì œí•œ
export OLLAMA_NUM_GPU=0      # GPU ë¯¸ì‚¬ìš©
```

### Q7: API ì„œë²„ì˜ ì‘ë‹µì´ ëŠë¦½ë‹ˆë‹¤.

**A:** ë‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:

1. **ë” ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©:**
   ```bash
   ollama pull neural-chat  # Mistralë³´ë‹¤ ë¹ ë¦„
   ```

2. **Whisper ëª¨ë¸ ìµœì í™”:**
   ```python
   # tiny ë˜ëŠ” small ëª¨ë¸ ì‚¬ìš©
   export WHISPER_MODEL=small
   ```

3. **ë©€í‹° ìŠ¤ë ˆë”© í™œì„±í™”:**
   ```bash
   export OLLAMA_NUM_THREAD=8
   ```

### Q8: ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì™€ Python ë²„ì „ì´ ì¶©ëŒí•©ë‹ˆë‹¤.

**A:** pyenvë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ Python ë²„ì „ì„ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# pyenv ì„¤ì¹˜
brew install pyenv

# ì—¬ëŸ¬ Python ë²„ì „ ì„¤ì¹˜
pyenv install 3.10.19
pyenv install 3.11.0

# í”„ë¡œì íŠ¸ë³„ ë²„ì „ ì„¤ì •
cd ~/Desktop/contextllm
pyenv local 3.10.19

cd ~/Desktop/other_project
pyenv local 3.11.0
```

### Q9: Windowsì—ì„œ ìŒì„± ë…¹ìŒ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.

**A:** PyAudio ë˜ëŠ” sounddeviceë¥¼ ì„¤ì¹˜í•˜ê³  voice_analyzer.pyë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.

```bash
# sounddevice ì„¤ì¹˜ (ê¶Œì¥)
pip install sounddevice scipy

# ë˜ëŠ” PyAudio ì„¤ì¹˜ (ë³µì¡í•  ìˆ˜ ìˆìŒ)
pip install pyaudio
```

ê·¸ í›„ [voice_analyzer.py](voice_analyzer.py)ì˜ `record_audio()` ë©”ì„œë“œë¥¼ Windows ë²„ì „ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”. (ìœ„ì˜ "ğŸªŸ Windows" ì„¹ì…˜ ì°¸ê³ )

### Q10: Linuxì—ì„œ ë§ˆì´í¬ ê¶Œí•œ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.

**A:** ì‚¬ìš©ìë¥¼ audio ê·¸ë£¹ì— ì¶”ê°€í•˜ì„¸ìš”.

```bash
# í˜„ì¬ ì‚¬ìš©ìë¥¼ audio ê·¸ë£¹ì— ì¶”ê°€
sudo usermod -aG audio $USER

# ë˜ëŠ” ì„ì‹œë¡œ ê¶Œí•œ ì£¼ê¸°
sudo usermod -aG audio $(whoami)

# ê·¸ë£¹ ë³€ê²½ ë°˜ì˜ (ì¬ë¶€íŒ… ë˜ëŠ” ìƒˆ í„°ë¯¸ë„)
newgrp audio

# í™•ì¸
groups
# audioê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
```

### Q11: Dockerì—ì„œ ì‹¤í–‰ ì‹œ ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

**A:** Docker ì»¨í…Œì´ë„ˆì— í˜¸ìŠ¤íŠ¸ì˜ ë§ˆì´í¬ ì ‘ê·¼ê¶Œí•œì„ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.

```bash
# macOS
docker run -it --device /dev/snd voice-analyzer

# Linux
docker run -it --device /dev/snd:/dev/snd -v /run/user/1000/pulse:/run/user/1000/pulse voice-analyzer

# Windows (WSL2)
docker run -it --device /dev/snd voice-analyzer
```

### Q12: OSë³„ í˜¸í™˜ì„± ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.

**A:** ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:

| ê¸°ëŠ¥ | macOS | Windows | Linux |
|------|-------|---------|-------|
| ìŒì„± ë…¹ìŒ | âœ… Sox | âš ï¸ PyAudio/sounddevice | âœ… Sox |
| Ollama | âœ… | âœ… | âœ… |
| Whisper | âœ… | âœ… | âœ… |
| REST API | âœ… | âœ… | âœ… |
| Python 3.10.19 | âœ… | âœ… | âœ… |

**Windows ì‚¬ìš©ì:**
- PyAudio ì„¤ì¹˜ ì‹œ Visual Studio Build Tools í•„ìš”
- ë˜ëŠ” sounddevice ì‚¬ìš© ê¶Œì¥
- requirements.txtì— `sounddevice` ì¶”ê°€ í•„ìš”

**Linux ì‚¬ìš©ì:**
- PulseAudio/ALSA ì„¤ì • í•„ìš”í•  ìˆ˜ ìˆìŒ
- ë§ˆì´í¬ ê¶Œí•œ(audio ê·¸ë£¹) í•„ìš”

**ëª¨ë“  OS:**
- Python 3.10.19 í•„ìˆ˜ (í˜¸í™˜ì„±)
- Ollama ì„œë²„ ë°˜ë“œì‹œ ì‹¤í–‰ ì¤‘
- ì¸í„°ë„· ì—°ê²° í•„ìš” (ì´ˆê¸° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œ)


---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

1. **ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ ì‘ì„±** - `SETUP_GUIDE.md`ì˜ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì°¸ê³ 
2. **VS Code í™•ì¥ ê°œë°œ** - `src/extension.ts`ì—ì„œ í”ŒëŸ¬ê·¸ì¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•
3. **ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™** - ê²°ê³¼ë¥¼ MongoDB/PostgreSQLì— ì €ì¥
4. **í´ë¼ìš°ë“œ ë°°í¬** - Azure/AWSì— ë°°í¬
5. **íŒ€ í˜‘ì—…** - GitHubì— í‘¸ì‹œí•˜ê³  í˜‘ì—… ì‹œì‘

---

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ë©´:

1. **ë¡œê·¸ í™•ì¸**: `transcriptions/` ë””ë ‰í† ë¦¬ì˜ ê²°ê³¼ íŒŒì¼ í™•ì¸
2. **í…ŒìŠ¤íŠ¸ ì‹¤í–‰**: `test_*.py` íŒŒì¼ ì‹¤í–‰
3. **GitHub Issues**: ë²„ê·¸ ë¦¬í¬íŠ¸ ì œì¶œ
4. **ë¬¸ì„œ ì°¸ê³ **: `SETUP_GUIDE.md`, `OLLAMA_GUIDE.md`, `REAL_TEST_GUIDE.md`

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” **MIT ë¼ì´ì„ ìŠ¤**ë¥¼ ë”°ë¦…ë‹ˆë‹¤.

---

## ğŸ™ ê°ì‚¬ì˜ ë§

- [OpenAI Whisper](https://github.com/openai/whisper) - ìŒì„± ì¸ì‹
- [Ollama](https://ollama.ai) - LLM ë¡œì»¬ ì‹¤í–‰
- [PyTorch](https://pytorch.org) - ë¨¸ì‹  ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2026ë…„ 1ì›” 22ì¼  
**Python ë²„ì „**: 3.10.19  
**ìƒíƒœ**: âœ… í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ
