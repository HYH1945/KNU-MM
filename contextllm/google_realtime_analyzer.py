#!/usr/bin/env python3
"""
Google Cloud Speech-to-Text ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“ˆ
ë¬¸ì¥ë§ˆë‹¤ LLM ë¶„ì„ (ì§„ì •í•œ ì‹¤ì‹œê°„!)

ì„¤ì¹˜:
    pip install google-cloud-speech pyaudio
    
ì¸ì¦:
    export GOOGLE_APPLICATION_CREDENTIALS="/path/to/credentials.json"
"""

import os
import json
import requests
from datetime import datetime
from pathlib import Path
from collections import deque

try:
    from google.cloud import speech_v1
    from google.api_core.gapic_v1 import client_info as grpc_client_info
    import pyaudio
    GOOGLE_AVAILABLE = True
except ImportError:
    GOOGLE_AVAILABLE = False
    print("âš ï¸  Google Cloud Speech ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   ì„¤ì¹˜: pip install google-cloud-speech pyaudio")

class GoogleRealtimeAnalyzer:
    """Google Cloud Speech-to-Text + ì‹¤ì‹œê°„ LLM ë¶„ì„"""
    
    def __init__(self, ollama_url="http://localhost:11434"):
        if not GOOGLE_AVAILABLE:
            raise ImportError("google-cloud-speechì™€ pyaudioê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        self.client = speech_v1.SpeechClient()
        self.ollama_url = ollama_url
        self.results_dir = "./transcriptions"
        Path(self.results_dir).mkdir(exist_ok=True)
        
        # ë¶€ë¶„ ê²°ê³¼ ì €ì¥ì†Œ
        self.interim_results = deque(maxlen=10)
        self.final_results = []
    
    def stream_audio(self, sample_rate=16000, chunk_duration=0.1):
        """ë§ˆì´í¬ì—ì„œ ì‹¤ì‹œê°„ ìŒì„± ìŠ¤íŠ¸ë¦¬ë°"""
        audio = pyaudio.PyAudio()
        
        stream = audio.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=sample_rate,
            input=True,
            frames_per_buffer=int(sample_rate * chunk_duration)
        )
        
        try:
            print("ğŸ¤ ë§ˆì´í¬ ì…ë ¥ ì¤‘... (Ctrl+Cë¡œ ì¢…ë£Œ)")
            while True:
                chunk = stream.read(int(sample_rate * chunk_duration))
                if chunk:
                    yield chunk
        except KeyboardInterrupt:
            print("\nâ¹ï¸  ë…¹ìŒ ì¤‘ì§€")
        finally:
            stream.stop_stream()
            stream.close()
            audio.terminate()
    
    def analyze_sentence(self, text, system_prompt=None):
        """ë¬¸ì¥ì„ LLMìœ¼ë¡œ ë¶„ì„"""
        try:
            analysis_prompt = system_prompt or """
ë‹¤ìŒ ë¬¸ì¥ì„ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
{
  "emotion": "ê¸ì •/ì¤‘ë¦½/ë¶€ì •",
  "urgency": "ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ/ê¸´ê¸‰",
  "intent": "ì˜ë„ ìš”ì•½",
  "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
}
"""
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": "mistral",
                    "prompt": f"{analysis_prompt}\n\në¬¸ì¥: {text}",
                    "stream": False,
                    "format": "json"
                },
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                try:
                    analysis = json.loads(result.get('response', '{}'))
                    return analysis
                except:
                    return {"raw": result.get('response', '')}
            return {"error": "LLM ë¶„ì„ ì‹¤íŒ¨"}
        
        except Exception as e:
            return {"error": str(e)}
    
    def listen_and_analyze_realtime(self, system_prompt=None, max_duration=None):
        """
        ì‹¤ì‹œê°„ìœ¼ë¡œ ìŒì„±ì„ ë“£ê³  ë¬¸ì¥ë§ˆë‹¤ ë¶„ì„ (ì§„ì •í•œ ì‹¤ì‹œê°„!)
        
        Args:
            system_prompt: LLM ë¶„ì„ í”„ë¡¬í”„íŠ¸
            max_duration: ìµœëŒ€ ì‹¤í–‰ ì‹œê°„ (ì´ˆ)
        
        Returns:
            ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        import time
        
        config = speech_v1.RecognitionConfig(
            encoding=speech_v1.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code="ko-KR",
            enable_automatic_punctuation=True,
            max_alternatives=1,
        )
        
        streaming_config = speech_v1.StreamingRecognitionConfig(
            config=config,
            interim_results=True
        )
        
        results = []
        start_time = time.time()
        current_sentence = ""
        last_analysis_time = 0
        
        print(f"\n{'='*60}")
        print("âš¡ Google Speech-to-Text ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")
        print("ë¬¸ì¥ì´ ì™„ì„±ë˜ë©´ ìë™ìœ¼ë¡œ LLM ë¶„ì„")
        print(f"{'='*60}\n")
        
        try:
            # ìŒì„± ìŠ¤íŠ¸ë¦¼ ìƒì„±
            requests_gen = (
                speech_v1.StreamingRecognizeRequest(audio_content=chunk)
                for chunk in self.stream_audio()
            )
            
            # ì‹¤ì‹œê°„ ì¸ì‹
            responses = self.client.streaming_recognize(
                streaming_config,
                requests_gen
            )
            
            for response in responses:
                # ìµœëŒ€ ì‹œê°„ ì²´í¬
                if max_duration and (time.time() - start_time) > max_duration:
                    print(f"\nâ° {max_duration}ì´ˆ ê²½ê³¼ - ì¢…ë£Œ")
                    break
                
                if not response.results:
                    continue
                
                result = response.results[0]
                
                if result.alternatives:
                    transcript = result.alternatives[0].transcript
                    
                    if result.is_final:
                        # ğŸŸ¢ ìµœì¢… ê²°ê³¼ (ë¬¸ì¥ ì™„ì„±)
                        print(f"\nâœ… [ìµœì¢…] {transcript}")
                        
                        # ë¬¸ì¥ì´ ëë‚¬ìœ¼ë¯€ë¡œ ë¶„ì„ ì‹¤í–‰
                        current_sentence += transcript
                        
                        print(f"ğŸ§  LLM ë¶„ì„ ì¤‘...")
                        analysis = self.analyze_sentence(current_sentence, system_prompt)
                        
                        # ê²°ê³¼ ì¶œë ¥
                        print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼:")
                        if 'error' not in analysis:
                            if 'emotion' in analysis:
                                print(f"  ğŸ˜Š ê°ì •: {analysis['emotion']}")
                            if 'urgency' in analysis:
                                print(f"  ğŸš¨ ìœ„ê¸‰ë„: {analysis['urgency']}")
                            if 'intent' in analysis:
                                print(f"  ğŸ’­ ì˜ë„: {analysis['intent']}")
                            if 'keywords' in analysis:
                                print(f"  ğŸ·ï¸  í‚¤ì›Œë“œ: {', '.join(analysis['keywords'])}")
                        else:
                            print(f"  âŒ {analysis['error']}")
                        
                        # ê²°ê³¼ ì €ì¥
                        entry = {
                            'timestamp': datetime.now().isoformat(),
                            'text': current_sentence,
                            'analysis': analysis
                        }
                        results.append(entry)
                        self.final_results.append(entry)
                        
                        # ë‹¤ìŒ ë¬¸ì¥ ì¤€ë¹„
                        current_sentence = ""
                    else:
                        # ğŸŸ¡ ë¶€ë¶„ ê²°ê³¼ (ì…ë ¥ ì¤‘...)
                        print(f"\râ³ [ì…ë ¥ì¤‘] {transcript[:60]}...", end="", flush=True)
                        current_sentence = transcript
        
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜: {e}")
        
        finally:
            # ê²°ê³¼ ì €ì¥
            self._save_results(results)
            
            print(f"\n\n{'='*60}")
            print(f"ğŸ“Š ì²˜ë¦¬ ì™„ë£Œ")
            print(f"âœ… ë¶„ì„ëœ ë¬¸ì¥: {len(results)}ê°œ")
            print(f"{'='*60}")
        
        return results
    
    def _save_results(self, results):
        """ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥"""
        if not results:
            return
        
        date_folder = f"{self.results_dir}/{datetime.now().strftime('%Y-%m-%d')}"
        Path(date_folder).mkdir(exist_ok=True)
        
        # JSON ì €ì¥
        json_file = f"{date_folder}/google_realtime_{datetime.now().strftime('%H%M%S')}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {json_file}")


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    if not GOOGLE_AVAILABLE:
        print("âŒ Google Cloud Speech-to-Textì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("\nì„¤ì¹˜ ë°©ë²•:")
        print("  1. pip install google-cloud-speech pyaudio")
        print("  2. Google Cloud ì¸ì¦: export GOOGLE_APPLICATION_CREDENTIALS=...")
        exit(1)
    
    analyzer = GoogleRealtimeAnalyzer()
    
    print("Google Cloud Speech-to-Text ì‹¤ì‹œê°„ ë¶„ì„ ì‹œì‘")
    print("=" * 60)
    print("ë§ˆì´í¬ë¡œ ë§í•˜ì„¸ìš”. ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì‹¤ì‹œê°„ ë¶„ì„ë©ë‹ˆë‹¤.")
    print("Ctrl+Cë¡œ ì¢…ë£Œ")
    print("=" * 60)
    
    # ì‹¤ì‹œê°„ ë¶„ì„ ì‹¤í–‰ (ìµœëŒ€ 60ì´ˆ)
    results = analyzer.listen_and_analyze_realtime(max_duration=60)
    
    print("\nìµœì¢… ê²°ê³¼:")
    for i, result in enumerate(results, 1):
        print(f"\n[{i}] {result['text']}")
        print(f"   ë¶„ì„: {result['analysis']}")
