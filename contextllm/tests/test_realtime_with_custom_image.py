#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ + ì‚¬ìš©ì ì§€ì • ì´ë¯¸ì§€ ë©€í‹°ëª¨ë‹¬ ë¶„ì„
ë§ˆì´í¬ë¡œ ì‹¤ì‹œê°„ ì…ë ¥ + ë¯¸ë¦¬ ì¤€ë¹„í•œ ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ë¶„ì„

ì‚¬ìš©ë²•:
  1. test_images/ í´ë”ì— ë¶„ì„í•  ì´ë¯¸ì§€ ë„£ê¸°
  2. python tests/test_realtime_with_custom_image.py
  3. ì´ë¯¸ì§€ ì„ íƒ
  4. ë§ˆì´í¬ë¡œ ë§í•˜ë©´ ìë™ìœ¼ë¡œ ì„ íƒí•œ ì´ë¯¸ì§€ì™€ í•¨ê»˜ ë¶„ì„
"""

import sys
import os
from pathlib import Path
from datetime import datetime
import json
import tempfile

# src í´ë”ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
env_path = Path(__file__).parent.parent / 'config' / '.env'
load_dotenv(env_path)

import speech_recognition as sr
from core.multimodal_analyzer import MultimodalAnalyzer
from core.alert_manager import get_alert_manager

# ê¸€ë¡œë²Œ alert manager ì´ˆê¸°í™”
alert_manager = get_alert_manager()

# ë””ë ‰í† ë¦¬ ì„¤ì •
TEST_IMAGES_DIR = Path(__file__).parent.parent / 'test_images'
TEST_IMAGES_DIR.mkdir(parents=True, exist_ok=True)

LOG_DIR = Path(__file__).parent.parent / 'data' / 'logs'
LOG_DIR.mkdir(parents=True, exist_ok=True)

# ì‹¤í–‰ ì‹œì‘ ì‹œê°„ìœ¼ë¡œ ë¡œê·¸ íŒŒì¼ëª… ìƒì„±
SESSION_START = datetime.now().strftime("%Y%m%d_%H%M%S")
LOG_FILE = LOG_DIR / f'realtime_custom_image_{SESSION_START}.json'

def save_conversation_log(turn, text, image_path, analysis):
    """ëŒ€í™” ë‚´ìš©ê³¼ ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ì— ê¸°ë¡"""
    # ê¸°ì¡´ ë¡œê·¸ ë¡œë“œ (ìˆìœ¼ë©´)
    if LOG_FILE.exists():
        with open(LOG_FILE, 'r', encoding='utf-8') as f:
            history = json.load(f)
    else:
        history = []
    
    # ìƒˆ ê¸°ë¡ ì¶”ê°€
    log_entry = {
        "turn": turn,
        "timestamp": datetime.now().isoformat(),
        "transcribed_text": text,
        "image_path": image_path,
        "analysis": analysis
    }
    history.append(log_entry)
    
    # íŒŒì¼ì— ì €ì¥
    with open(LOG_FILE, 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)
    
    print(f"   ğŸ’¾ ê¸°ë¡ ì €ì¥ (ì´ {len(history)}ê±´): {LOG_FILE.name}")

# ìš°ì„ ìˆœìœ„ë³„ ìƒí™© ì„¤ëª…
SITUATION_GUIDE = {
    'CRITICAL': {
        'description': 'ğŸš¨ ê¸´ê¸‰ ìƒí™© - ì¦‰ì‹œ ëŒ€ì‘ í•„ìš”',
        'examples': ['ì„œë²„ ë‹¤ìš´', 'ë³´ì•ˆ ì¹¨í•´', 'ì‹œìŠ¤í…œ ì˜¤ë¥˜'],
    },
    'HIGH': {
        'description': 'âš ï¸ ë†’ì€ ìš°ì„ ìˆœìœ„ - ë¹ ë¥¸ ëŒ€ì‘ í•„ìš”',
        'examples': ['ì„±ëŠ¥ ì €í•˜', 'ì‚¬ìš©ì ë¶ˆë§Œ', 'ì˜¤ë¥˜ ë°œìƒ'],
    },
    'MEDIUM': {
        'description': 'ğŸ“Œ ì¤‘ê°„ ìš°ì„ ìˆœìœ„ - ì¼ë°˜ì  ëŒ€ì‘',
        'examples': ['ì¼ë°˜ ì§ˆë¬¸', 'ì •ë³´ ì œê³µ', 'ê¸°íƒ€'],
    },
    'LOW': {
        'description': 'â„¹ï¸ ë‚®ì€ ìš°ì„ ìˆœìœ„ - ë°°ê²½ ì •ë³´',
        'examples': ['ì¸ì‚¬', 'ì¼ë°˜ ëŒ€í™”', 'ì°¸ê³  ì‚¬í•­'],
    }
}

print("=" * 70)
print("ğŸ¤ ì‹¤ì‹œê°„ ìŒì„± + ì‚¬ìš©ì ì§€ì • ì´ë¯¸ì§€ ë©€í‹°ëª¨ë‹¬ ë¶„ì„")
print("=" * 70)

# ì´ë¯¸ì§€ í´ë” í™•ì¸
image_files = list(TEST_IMAGES_DIR.glob('*'))
image_files = [f for f in image_files if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.gif']]

if not image_files:
    print(f"\nâš ï¸  {TEST_IMAGES_DIR} í´ë”ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!")
    print(f"\nğŸ“Œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”:")
    print(f"   1. ì´ë¯¸ì§€ë¥¼ {TEST_IMAGES_DIR} í´ë”ì— ë³µì‚¬")
    print(f"   2. ë‹¤ì‹œ ì‹¤í–‰")
    exit(1)

print(f"\nâœ… {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬:")
for i, img_file in enumerate(image_files, 1):
    file_size = img_file.stat().st_size / 1024  # KB
    print(f"   {i}. {img_file.name} ({file_size:.1f} KB)")

# ì´ë¯¸ì§€ ì„ íƒ
print("\n" + "=" * 70)
print("ğŸ“¸ ë¶„ì„ì— ì‚¬ìš©í•  ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”")
print("=" * 70)

selected_image = None

try:
    choice = input(f"\nì´ë¯¸ì§€ ë²ˆí˜¸ ì„ íƒ (1-{len(image_files)}): ")
    choice_num = int(choice)
    
    if 1 <= choice_num <= len(image_files):
        selected_image = str(image_files[choice_num - 1])
        print(f"âœ… ì„ íƒëœ ì´ë¯¸ì§€: {image_files[choice_num - 1].name}")
    else:
        print("âŒ ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤")
        exit(1)
except ValueError:
    print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
    exit(1)

print(f"\nğŸ’¡ ì´ì œ ë§ˆì´í¬ë¡œ ë§í•˜ë©´ '{Path(selected_image).name}' ì´ë¯¸ì§€ì™€ í•¨ê»˜ ë¶„ì„ë©ë‹ˆë‹¤")
print("ğŸ’¡ 'quit' ë˜ëŠ” 'exit'ì„ ë§í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤\n")

# 1. ëª¨ë“ˆ ë¡œë“œ
print("1ï¸âƒ£ ëª¨ë“ˆ ë¡œë“œ ì¤‘...")
try:
    multimodal_analyzer = MultimodalAnalyzer()
    recognizer = sr.Recognizer()
    print("   âœ… ëª¨ë“  ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    print(f"   âŒ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit(1)

# 2. ë¬´í•œ ë£¨í”„ ëª¨ë‹ˆí„°ë§
print("\n" + "=" * 70)
print("âœ… ì‹œì‘ ì¤€ë¹„ ì™„ë£Œ! ë§ˆì´í¬ë¡œ ë§ì”€í•´ì£¼ì„¸ìš”")
print("=" * 70 + "\n")

turn = 1
while True:
    try:
        print(f"\nğŸ“ [íšŒì°¨ {turn}] ë§ˆì´í¬ì—ì„œ ì…ë ¥ ë°›ëŠ” ì¤‘...")
        print("   ğŸ’¬ ì§€ê¸ˆë¶€í„° ë§ì”€í•´ì£¼ì„¸ìš” ('quit' ë˜ëŠ” 'exit'ìœ¼ë¡œ ì¢…ë£Œ)")
        
        with sr.Microphone() as source:
            # ë°°ê²½ ì†ŒìŒ ì ì‘
            recognizer.adjust_for_ambient_noise(source, duration=1)
            
            # ìŒì„± ì…ë ¥ (ìµœëŒ€ 30ì´ˆ)
            audio = recognizer.listen(source, timeout=None, phrase_time_limit=30)
        
        # Google Speech Recognition (ë¬´ë£Œ)
        print("   ğŸ”„ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")
        text = recognizer.recognize_google(audio, language='ko-KR')
        
        # ì¢…ë£Œ ì¡°ê±´
        if text.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'ë']:
            print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤")
            break
        
        print(f"\n   ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:")
        print(f"      '{text}'")
        
        # ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ (ìŒì„± íŠ¹ì„± ë¶„ì„ìš©)
        temp_audio_file = None
        try:
            print("   ğŸ’¾ ì˜¤ë””ì˜¤ ë°ì´í„° ì €ì¥ ì¤‘...")
            
            # WAV ë°ì´í„° ì¶”ì¶œ
            wav_data = audio.get_wav_data()
            
            # ì„ì‹œ íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
                temp_audio_file = f.name
                f.write(wav_data)
            
            print(f"      âœ… ì„ì‹œ íŒŒì¼ ì €ì¥: {temp_audio_file}")
            
            # ë©€í‹°ëª¨ë‹¬ ë¶„ì„ (ìŒì„± + ì„ íƒí•œ ì´ë¯¸ì§€ + ìŒì„± íŠ¹ì„±)
            print(f"\n   ğŸ¤– ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì¤‘ (ìŒì„± + ì´ë¯¸ì§€ + ìŒì„± íŠ¹ì„±: {Path(selected_image).name})...")
            
            analysis = multimodal_analyzer.analyze_with_image(
                audio_text=text, 
                image_source=selected_image,
                audio_file_path=temp_audio_file  # ìŒì„± íŠ¹ì„± ë¶„ì„ í¬í•¨!
            )
            print("      âœ… ë¶„ì„ ì™„ë£Œ\n")
            
            priority = analysis.get('priority', 'LOW')
            is_emergency = analysis.get('is_emergency', False)
            
            # ğŸš¨ ê¸´ê¸‰ ìƒí™© ê°ì§€ ë° ì•Œë¦¼ (alert_manager ì‚¬ìš©)
            if is_emergency or priority == 'CRITICAL':
                alert_manager.trigger_alert({
                    'is_emergency': is_emergency,
                    'emergency_reason': analysis.get('emergency_reason', 'ì•Œ ìˆ˜ ì—†ëŠ” ê¸´ê¸‰ ìƒí™©'),
                    'priority': priority,
                    'situation_type': analysis.get('situation_type', 'ë¯¸ë¶„ë¥˜')
                })
            
            # ìƒí™© ë¶„ì„
            situation_text = analysis.get('situation', 'ë¯¸ë¶„ë¥˜')
            print(f"   ğŸ¯ ìƒí™© ë¶„ì„:")
            print(f"      {situation_text}")
            
            # ì‹œê°ì  ë‚´ìš©
            visual_content = analysis.get('visual_content', 'N/A')
            if visual_content and visual_content != 'N/A':
                print(f"\n   ğŸ‘ï¸  ì‹œê° ì •ë³´:")
                print(f"      {visual_content}")
            
            # ìŒì„±-ì‹œê° ì¼ì¹˜ë„
            consistency = analysis.get('audio_visual_consistency', 'N/A')
            if consistency and consistency != 'N/A':
                consistency_emoji = {
                    'ì¼ì¹˜': 'âœ…',
                    'ë¶ˆì¼ì¹˜': 'âš ï¸',
                    'ë¶€ë¶„ì¼ì¹˜': 'ğŸ”¶'
                }.get(consistency, 'â“')
                print(f"\n   {consistency_emoji} ìŒì„±-ì‹œê° ì¼ì¹˜ë„: {consistency}")
            
            situation_type = analysis.get('situation_type', 'ë¯¸ë¶„ë¥˜')
            print(f"\n   ğŸ“Œ ìƒí™© ìœ í˜•: {situation_type}")
            
            action = analysis.get('action', 'ë¯¸ë¶„ë¥˜')
            print(f"   ğŸ”§ ê¶Œì¥ ì¡°ì¹˜: {action}")
            
            # ìƒí™© ê°€ì´ë“œ (ì°¸ê³ ìš©)
            if priority in SITUATION_GUIDE:
                guide_info = SITUATION_GUIDE[priority]
                print(f"\n   {guide_info['description']}")
                print(f"   ğŸ“‹ ì°¸ê³  ì˜ˆì‹œ: {', '.join(guide_info['examples'])}")
            
            # ğŸ’¾ ê¸°ë¡ ì €ì¥
            save_conversation_log(turn, text, selected_image, analysis)
            
            print("\n   " + "=" * 65)
            turn += 1
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if temp_audio_file and os.path.exists(temp_audio_file):
                os.remove(temp_audio_file)
                print(f"   ğŸ—‘ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œë¨")
        
        
        
        # ìƒí™© ê°€ì´ë“œ (ì°¸ê³ ìš©)
        if priority in SITUATION_GUIDE:
            guide_info = SITUATION_GUIDE[priority]
            print(f"\n   {guide_info['description']}")
            print(f"   ğŸ“‹ ì°¸ê³  ì˜ˆì‹œ: {', '.join(guide_info['examples'])}")
        
        # ğŸ’¾ ê¸°ë¡ ì €ì¥
        save_conversation_log(turn, text, selected_image, analysis)
        
        print("\n   " + "=" * 65)
        turn += 1
        
    except sr.UnknownValueError:
        print("   âš ï¸  ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        turn += 1
    except sr.RequestError as e:
        print(f"   âŒ ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {e}")
        break
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤")
        break
    except Exception as e:
        print(f"   âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        turn += 1

print("\n" + "=" * 70)
print(f"âœ… ì´ {turn - 1}íšŒ ë¶„ì„ ì™„ë£Œ")
print(f"ğŸ“ ì‚¬ìš©í•œ ì´ë¯¸ì§€: {Path(selected_image).name}")
print("=" * 70)
